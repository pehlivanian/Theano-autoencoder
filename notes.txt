z = self.decorated.predict(*a, **k)
for _ in range(n):
    z = self.decorated.predict_from_input( z - self.y )
return z

n=0
===
POST PRETRAIN Non-symmetric case
DA LAYERS
=========
layer: 0  W:125 x 100    b: 1x100   pretrain cost: 2.893040
layer: 1  W:100 x 75     b: 1x75   pretrain cost: 0.054244

MLP LAYERS
==========
finetune cost: 21.667209
layer: 0  W:125 x 100    b: 1x100
layer: 1  W:100 x 75     b: 1x75

POST FINETUNE Non-symmetric case
DA LAYERS
=========
layer: 0  W:125 x 100    b: 1x100   pretrain cost: 5.301696
layer: 1  W:100 x 75     b: 1x75   pretrain cost: 4.598993

MLP LAYERS
==========
finetune cost: 0.401892
layer: 0  W:125 x 100    b: 1x100
layer: 1  W:100 x 75     b: 1x75

DA 
LAYERS
======
cost: 0.331426
layer: 0  W:125 x 75     b: 1x75

n = 3
=====
POST PRETRAIN Non-symmetric case
DA LAYERS
=========
layer: 0  W:125 x 100    b: 1x100   pretrain cost: 2.875702
layer: 1  W:100 x 75     b: 1x75   pretrain cost: 0.015137

MLP LAYERS
==========
finetune cost: 18.115777
layer: 0  W:125 x 100    b: 1x100
layer: 1  W:100 x 75     b: 1x75

POST FINETUNE Non-symmetric case
DA LAYERS
=========
layer: 0  W:125 x 100    b: 1x100   pretrain cost: 4.488555
layer: 1  W:100 x 75     b: 1x75   pretrain cost: 4.848953

MLP LAYERS
==========
finetune cost: 0.271208
layer: 0  W:125 x 100    b: 1x100
layer: 1  W:100 x 75     b: 1x75

DA 
LAYERS
======
cost: 0.331426
layer: 0  W:125 x 75     b: 1x75

